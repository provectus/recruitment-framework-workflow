# Technical Specification: Infrastructure — AWS Environment & CI/CD

- **Functional Specification:** `context/spec/002-infrastructure/functional-spec.md`
- **Status:** Completed
- **Author(s):** Claude (AI-assisted)

---

## 1. High-Level Technical Approach

Provision a single POC environment in **us-east-1** using **Terraform** with modular structure. The FastAPI backend runs on **ECS Fargate** behind an **ALB** at `api.<domain>`. The React SPA is served from **S3 + CloudFront** at `<domain>`. **RDS PostgreSQL** (db.t4g.micro) in a private subnet stores application data. **GitHub Actions** deploys on push to `main` using OIDC for AWS authentication.

The frontend communicates with the API via a **separate subdomain** (CORS-based). The existing Dockerfile's `prod` stage is used as-is for ECS. Bedrock access is enabled via IAM role attached to ECS tasks.

---

## 2. Proposed Solution & Implementation Plan (The "How")

### 2.1 Repository Layout

```
infra/
  main.tf                    # Provider config, terraform backend
  variables.tf               # Root variables (region, project name, domain, etc.)
  outputs.tf                 # Key outputs (CloudFront URL, ALB DNS, RDS endpoint)
  modules/
    networking/              # VPC, subnets, IGW, NAT, security groups
    ecs/                     # Cluster, service, task def, ALB, ECR, target group
    rds/                     # PostgreSQL instance, subnet group, parameter group
    s3/                      # SPA bucket, files bucket, CloudFront OAC
    cloudfront/              # Distribution, cache behaviors, custom error responses
    acm/                     # Certificate + DNS validation
    iam/                     # OIDC provider, GitHub Actions role, ECS task/execution roles
    cognito/                 # User Pool, Google IdP, app client, hosted UI domain
    monitoring/              # CloudWatch log groups, alarms
.github/
  workflows/
    deploy-backend.yml       # Backend CI/CD pipeline
    deploy-frontend.yml      # Frontend CI/CD pipeline
```

### 2.2 Networking Module (`modules/networking/`)

| Resource | Details |
|----------|---------|
| VPC | `10.0.0.0/16` CIDR, DNS hostnames enabled |
| Public subnets | `10.0.1.0/24`, `10.0.2.0/24` in us-east-1a, us-east-1b — ALB, NAT Gateway |
| Private subnets | `10.0.10.0/24`, `10.0.11.0/24` — ECS tasks, RDS |
| Internet Gateway | Attached to VPC, route from public subnets |
| NAT Gateway | Single NAT in one public subnet (cost savings for POC), route from private subnets |
| Security Groups | `alb-sg` (443 inbound from 0.0.0.0/0), `ecs-sg` (8000 from alb-sg), `rds-sg` (5432 from ecs-sg) |

### 2.3 ECS Module (`modules/ecs/`)

| Resource | Details |
|----------|---------|
| ECR Repository | `tap-backend` — stores Docker images pushed by CI |
| ECS Cluster | `tap-cluster`, Fargate capacity provider |
| Task Definition | Fargate, 0.25 vCPU / 0.5 GB (POC sizing), `prod` stage of existing Dockerfile |
| Container config | Port 8000, health check path `/health`, env vars from Secrets Manager + SSM |
| ECS Service | Desired count: 1, deployment circuit breaker enabled (auto-rollback), private subnets |
| ALB | Internet-facing in public subnets, HTTPS listener (ACM cert), HTTP → HTTPS redirect |
| Target Group | Port 8000, health check `/health`, deregistration delay 30s |

Environment variables injected into the container:
- `DATABASE_URL` — from Secrets Manager
- `JWT_SECRET_KEY` — from Secrets Manager
- `COGNITO_*` — from SSM Parameter Store (or Secrets Manager for client secret)
- `CORS_ORIGINS` — set to `["https://<domain>"]`
- `COOKIE_DOMAIN` — `.<domain>`
- `COOKIE_SECURE` — `true`

### 2.4 RDS Module (`modules/rds/`)

| Resource | Details |
|----------|---------|
| Instance | `db.t4g.micro`, PostgreSQL 16, 20 GB gp3 storage |
| Subnet group | Private subnets |
| Security | `rds-sg`, no public access, encrypted at rest (default KMS) |
| Credentials | Generated by RDS, stored in Secrets Manager (via `manage_master_user_password`) |
| Backups | Automated, 7-day retention |
| Parameter group | Default PostgreSQL 16 params |

### 2.5 S3 Module (`modules/s3/`)

| Bucket | Purpose | Access |
|--------|---------|--------|
| `tap-spa-<account-id>` | React SPA static assets | CloudFront OAC (Origin Access Control), no public access |
| `tap-files-<account-id>` | CVs, transcripts (future) | Presigned URLs from backend, no public access |

Both buckets: versioning enabled, server-side encryption (SSE-S3), block all public access.

### 2.6 CloudFront + ACM Modules

**ACM (`modules/acm/`):**
- Wildcard certificate: `*.<domain>` + `<domain>`
- DNS validation (records output for manual creation if no Route53 zone yet)

**CloudFront (`modules/cloudfront/`):**

| Setting | Value |
|---------|-------|
| Origin | S3 bucket via OAC |
| Default root object | `index.html` |
| Custom error response | 403/404 → `/index.html` with 200 (SPA fallback) |
| Cache policy | `CachingOptimized` for static assets |
| Alternate domain | `<domain>` |
| Certificate | ACM cert from above |
| Price class | `PriceClass_100` (US/EU only — cost savings) |

The **API** is NOT proxied through CloudFront. It gets its own ALB with an ACM cert for `api.<domain>`.

### 2.7 IAM Module (`modules/iam/`)

| Role | Purpose | Key Policies |
|------|---------|-------------|
| `tap-ecs-execution-role` | ECS task startup | Pull from ECR, read Secrets Manager, write CloudWatch Logs |
| `tap-ecs-task-role` | Runtime permissions for the app | S3 read/write (`tap-files-*`), Bedrock `InvokeModel`, Secrets Manager read |
| `tap-github-actions-role` | CI/CD deployments | Push to ECR, update ECS service, S3 sync (SPA bucket), CloudFront invalidation |
| OIDC Provider | GitHub → AWS trust | `token.actions.githubusercontent.com`, audience `sts.amazonaws.com` |

GitHub Actions role trust policy: restrict to `repo:<org>/<repo>:ref:refs/heads/main`.

### 2.8 Cognito Module (`modules/cognito/`)

| Resource | Details |
|----------|---------|
| User Pool | `tap-users`, email as username attribute, no self-signup (admin-only or federated) |
| Google Identity Provider | Federated IdP using Google OAuth credentials (client ID + secret from Google Cloud Console) |
| App Client | `tap-web-client`, authorization code grant, scopes: `openid email profile`, callback URL: `https://api.<domain>/auth/callback`, sign-out URL: `https://<domain>/login` |
| User Pool Domain | Cognito hosted UI domain (e.g., `tap-auth.auth.us-east-1.amazoncognito.com`) or custom domain |

Outputs (stored in SSM Parameter Store, referenced by ECS task definition):
- `COGNITO_USER_POOL_ID` — SSM parameter
- `COGNITO_CLIENT_ID` — SSM parameter
- `COGNITO_CLIENT_SECRET` — Secrets Manager (sensitive)
- `COGNITO_DOMAIN` — SSM parameter
- `COGNITO_REDIRECT_URI` — set to `https://api.<domain>/auth/callback`

Google OAuth credentials (Google Cloud Console client ID + secret) are a **manual prerequisite** — must be created before `terraform apply` and passed as Terraform variables.

### 2.9 Bedrock

- Enable Claude model access in us-east-1 (manual step via AWS Console — Bedrock model access is a one-time approval, not Terraform-managed)
- The `tap-ecs-task-role` includes `bedrock:InvokeModel` permission scoped to Claude model ARN

### 2.10 Monitoring Module (`modules/monitoring/`)

| Resource | Details |
|----------|---------|
| Log group | `/ecs/tap-backend`, 30-day retention |
| ALB access logs | Enabled, stored in a dedicated S3 bucket |
| Alarm: ECS unhealthy | `TargetResponseTime` > 5s or `UnHealthyHostCount` > 0 for 5 min |
| Alarm: RDS CPU | `CPUUtilization` > 80% for 10 min |
| SNS topic | `tap-alerts` — email subscription (configured manually) |

### 2.11 GitHub Actions Pipelines

**Backend (`deploy-backend.yml`):**
```
trigger: push to main (paths: app/backend/**)
jobs:
  test:
    - checkout
    - setup python + uv
    - ruff check + ruff format --check
    - pytest
  deploy:
    needs: test
    - configure AWS via OIDC
    - build Docker image (prod target)
    - push to ECR
    - update ECS service (force new deployment)
    - wait for service stability
```

**Frontend (`deploy-frontend.yml`):**
```
trigger: push to main (paths: app/frontend/**)
jobs:
  test:
    - checkout
    - setup bun
    - bun run lint
    - bun run build (includes type-check)
  deploy:
    needs: test
    - configure AWS via OIDC
    - sync build output to S3
    - invalidate CloudFront cache
```

Both pipelines also run on PRs (test job only, no deploy) to provide status checks.

### 2.12 Terraform State Management

State stored remotely in S3 with DynamoDB locking. Created **manually** (one-time setup):

| Resource | Name | Purpose |
|----------|------|---------|
| S3 bucket | `tap-terraform-state-<account-id>` | State file storage, versioning enabled |
| DynamoDB table | `tap-terraform-locks` | State locking, partition key `LockID` |

Setup steps documented in `infra/README.md`.

---

## 3. Impact and Risk Analysis

### System Dependencies

- **Existing backend code:** Dockerfile is ready (multi-stage with `prod` target). Config reads from env vars — no code changes needed for deployment, just env var injection.
- **Existing frontend code:** `bun run build` produces static assets. Vite dev proxy (`/api`) is dev-only — production uses separate `api.<domain>` with CORS.
- **DNS:** Domain and DNS management are external dependencies. ACM validation requires DNS records to be created (manual step if no Route53 hosted zone).

### Potential Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|-----------|
| NAT Gateway cost | Single NAT is ~$32/mo + data transfer | Acceptable for POC. Document upgrade path to NAT per AZ for production. |
| Terraform state corruption | Could require manual recovery | S3 versioning enabled, DynamoDB locking prevents concurrent writes |
| ECR image not found on first deploy | ECS service fails to start | CI must push initial image before Terraform creates the ECS service, OR use an `initial_task_definition` approach with a placeholder image |
| ACM certificate pending validation | CloudFront/ALB won't serve HTTPS | Document DNS validation records clearly. Terraform will wait for validation. |
| Database migrations | Need to run Alembic after RDS is up | Add a migration step in the deploy pipeline (ECS run-task or pre-deploy step) |
| Secrets bootstrapping | First deploy needs secrets to exist | Document which Secrets Manager / SSM values must be created before first `terraform apply` |
| Google OAuth credentials | Cognito Google IdP requires Google Cloud Console OAuth client | Manual prerequisite — create Google OAuth app, pass client ID + secret as TF variables |

---

## 4. Testing Strategy

- **Terraform validation:** `terraform validate` and `terraform plan` in CI (on PRs to `infra/` paths) — ensures configs are syntactically correct
- **Smoke test after deploy:** Backend pipeline waits for ECS service stability, then hits `/health` endpoint through ALB
- **Frontend deploy verification:** CloudFront invalidation completes, curl the domain to verify `index.html` is served
- **Infrastructure drift:** Periodic `terraform plan` to detect manual changes (can be a scheduled GitHub Action later)
- **Existing test suites:** Backend `pytest` and frontend `bun run build` (which includes type-check) run as gate checks before any deployment
